# -*- coding: utf-8 -*-
"""Similarity_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HN8LMNz65YoYHvuib6XvDT8VcSSmwHO5
"""

import matplotlib.pyplot as plt
import numpy as np
from transformers import BertTokenizerFast, BertModel
import torch
from sklearn.metrics.pairwise import cosine_similarity
import spacy

# Load models
tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')
model.eval()
nlp = spacy.load("en_core_web_sm")

# Updated examples for 3 categories
word_examples = {
    # --- Nounâ€“Noun Homonyms (13) ---
    "bolt": {"type": "noun_noun",
             "noun1": "He tightened the bolt with a wrench.",
             "noun2": "A bolt of lightning struck the tree."},
    "chest": {"type": "noun_noun",
              "noun1": "He stored the blankets in the chest.",
              "noun2": "The pain was in the left side of his chest."},
    "court": {"type": "noun_noun",
              "noun1": "The players ran across the basketball court.",
              "noun2": "She appeared in court to testify."},
    "crane": {"type": "noun_noun",
              "noun1": "The crane lifted the heavy beam.",
              "noun2": "A crane flew over the marsh."},
    "deck": {"type": "noun_noun",
             "noun1": "He shuffled the deck of cards.",
             "noun2": "They stood on the upper deck of the ship."},
    "fan": {"type": "noun_noun",
            "noun1": "She turned on the fan to cool down.",
            "noun2": "The football fan cheered loudly."},
    "glass": {"type": "noun_noun",
              "noun1": "He drank water from a glass.",
              "noun2": "The window was made of stained glass."},
    "mint": {"type": "noun_noun",
             "noun1": "She grew mint in her herb garden.",
             "noun2": "The coins were made at the national mint."},
    "organ": {"type": "noun_noun",
              "noun1": "He played a tune on the church organ.",
              "noun2": "The liver is a vital organ."},
    "palm": {"type": "noun_noun",
             "noun1": "He had a cut on his palm.",
             "noun2": "The palm trees swayed in the breeze."},
    "ruler": {"type": "noun_noun",
              "noun1": "Use a ruler to draw a straight line.",
              "noun2": "The ruler of the kingdom was wise."},
    "straw": {"type": "noun_noun",
              "noun1": "She sipped juice through a straw.",
              "noun2": "The barn was filled with dry straw."},
    "temple": {"type": "noun_noun",
               "noun1": "The monk meditated inside the temple.",
               "noun2": "He had a bruise on his left temple."},

    # --- Nounâ€“Verb Homonyms (13) ---
    "bark": {"type": "noun_verb",
             "noun": "The tree's bark was rough.",
             "verb": "The dog barked all night."},
    "bowl": {"type": "noun_verb",
             "noun": "He ate soup from a large bowl.",
             "verb": "She bowled a perfect game."},
    "count": {"type": "noun_verb",
              "noun": "The final vote count was close.",
              "verb": "Please count how many chairs we need."},
    "fly": {"type": "noun_verb",
            "noun": "There was a fly buzzing in the room.",
            "verb": "Birds fly south in winter."},
    "hamper": {"type": "noun_verb",
               "noun": "She tossed dirty clothes in the hamper.",
               "verb": "The noise may hamper concentration."},
    "park": {"type": "noun_verb",
             "noun": "We had lunch in the park.",
             "verb": "He parked the car near the entrance."},
    "prune": {"type": "noun_verb",
              "noun": "She snacked on a dried prune.",
              "verb": "He pruned the hedge with care."},
    "register": {"type": "noun_verb",
                 "noun": "The cashier opened the register.",
                 "verb": "You must register for classes."},
    "ring": {"type": "noun_verb",
             "noun": "She wore a diamond ring.",
             "verb": "The bell rang loudly at noon."},
    "seal": {"type": "noun_verb",
             "noun": "A seal swam near the ice floe.",
             "verb": "He sealed the envelope."},
    "shed": {"type": "noun_verb",
             "noun": "The tools are kept in the shed.",
             "verb": "The snake sheds its skin."},
    "swallow": {"type": "noun_verb",
                "noun": "A swallow flew above the field.",
                "verb": "He swallowed the pill with water."},
    "train": {"type": "noun_verb",
              "noun": "The train arrived at the station.",
              "verb": "She trains every day for the race."},

    # --- Unambiguous Words (16) ---
    "acorn": {"type": "unambiguous",
              "sent1": "The squirrel picked up an acorn.",
              "sent2": "We found an acorn under the oak tree."},
    "doctor": {"type": "unambiguous",
               "sent1": "The doctor checked my temperature.",
               "sent2": "She became a doctor after medical school."},
    "groom": {"type": "unambiguous",
              "sent1": "The groom waited at the altar.",
              "sent2": "The groom wore a black tuxedo."},
    "hammer": {"type": "unambiguous",
               "sent1": "He used a hammer to drive the nail.",
               "sent2": "The hammer was lying in the toolbox."},
    "knife": {"type": "unambiguous",
              "sent1": "Be careful with that sharp knife.",
              "sent2": "He cut the rope with a knife."},
    "lobster": {"type": "unambiguous",
                "sent1": "She ordered lobster at the restaurant.",
                "sent2": "They caught a lobster in the trap."},
    "lock": {"type": "unambiguous",
             "sent1": "He turned the lock with a key.",
             "sent2": "The door wouldn't open without the lock."},
    "map": {"type": "unambiguous",
            "sent1": "He unfolded a map of the city.",
            "sent2": "We followed the map to the museum."},
    "mug": {"type": "unambiguous",
            "sent1": "She drank coffee from a mug.",
            "sent2": "He dropped the mug on the floor."},
    "pie": {"type": "unambiguous",
            "sent1": "I had a slice of apple pie.",
            "sent2": "The pie cooled on the windowsill."},
    "scissors": {"type": "unambiguous",
                 "sent1": "She cut paper with scissors.",
                 "sent2": "He picked up the scissors."},
    "skirt": {"type": "unambiguous",
              "sent1": "She wore a red skirt.",
              "sent2": "The skirt matched her shoes."},
    "sock": {"type": "unambiguous",
             "sent1": "He pulled on a warm sock.",
             "sent2": "The sock had a hole in it."},
    "tape": {"type": "unambiguous",
             "sent1": "He used tape to wrap the gift.",
             "sent2": "The tape wouldnâ€™t stick to the box."},
    "tie": {"type": "unambiguous",
            "sent1": "He wore a blue tie to work.",
            "sent2": "The tie was neatly knotted."},
    "window": {"type": "unambiguous",
               "sent1": "She opened the window for air.",
               "sent2": "Rain hit the windowpane."}
}

def get_embedding(sentence, target_word, expected_pos=None):
    doc = nlp(sentence)
    matched_token = None

    for token in doc:
        if token.lemma_ == target_word and (expected_pos is None or token.pos_.lower() == expected_pos.lower()):
            matched_token = token
            break

    if not matched_token:
        print(f"[!] '{target_word}' not found in: '{sentence}'")
        return None

    inputs = tokenizer(sentence, return_tensors='pt', return_offsets_mapping=True)
    offset_mapping = inputs.pop('offset_mapping')[0]
    with torch.no_grad():
        outputs = model(**inputs)
    token_embeddings = outputs.last_hidden_state.squeeze(0)

    start_char = matched_token.idx
    end_char = start_char + len(matched_token)

    matched_indices = [
        i for i, (start, end) in enumerate(offset_mapping)
        if start.item() >= start_char and end.item() <= end_char
    ]

    if not matched_indices:
        print(f"[!] Token not aligned. Using [CLS] fallback.")
        return token_embeddings[0].numpy()
    else:
        return token_embeddings[matched_indices].mean(dim=0).numpy()


# Run comparisons
results = {"noun_verb": [], "noun_noun": [], "unambiguous": []}

print("\n[###] Cosine Similarity by Word Type\n")

for word, entry in word_examples.items():
    if entry["type"] == "noun_verb":
        emb1 = get_embedding(entry["noun"], word, "noun")
        emb2 = get_embedding(entry["verb"], word, "verb")
    elif entry["type"] == "noun_noun":
        emb1 = get_embedding(entry["noun1"], word, "noun")
        emb2 = get_embedding(entry["noun2"], word, "noun")
    elif entry["type"] == "unambiguous":
        emb1 = get_embedding(entry["sent1"], word)
        emb2 = get_embedding(entry["sent2"], word)
    else:
        continue

    if emb1 is not None and emb2 is not None:
        sim = cosine_similarity([emb1], [emb2])[0][0]
        results[entry["type"]].append(sim)
        print(f"[{entry['type'].upper()}] {word}: similarity = {sim:.4f}")

# Summary stats
for category, sims in results.items():
    if sims:
        avg = sum(sims) / len(sims)
        print(f"\n[Summary] Average similarity for {category.upper()}: {avg:.4f}")
    else:
        print(f"\n[Summary] No valid scores for {category.upper()}.")

labels_nv = []
scores_nv = []
labels_nn = []
scores_nn = []
labels_u = []
scores_u = []

for word, entry in word_examples.items():
    if entry["type"] == "noun_verb":
        emb1 = get_embedding(entry["noun"], word, "noun")
        emb2 = get_embedding(entry["verb"], word, "verb")
        if emb1 is not None and emb2 is not None:
            sim = cosine_similarity([emb1], [emb2])[0][0]
            labels_nv.append(word)
            scores_nv.append(sim)

    elif entry["type"] == "noun_noun":
        emb1 = get_embedding(entry["noun1"], word, "noun")
        emb2 = get_embedding(entry["noun2"], word, "noun")
        if emb1 is not None and emb2 is not None:
            sim = cosine_similarity([emb1], [emb2])[0][0]
            labels_nn.append(word)
            scores_nn.append(sim)

    elif entry["type"] == "unambiguous":
        emb1 = get_embedding(entry["sent1"], word)
        emb2 = get_embedding(entry["sent2"], word)
        if emb1 is not None and emb2 is not None:
            sim = cosine_similarity([emb1], [emb2])[0][0]
            labels_u.append(word)
            scores_u.append(sim)


# Averages
avg_nv = np.mean(scores_nv)
avg_nn = np.mean(scores_nn)
avg_u = np.mean(scores_u)

# --- Plot individual bars ---
labels_all = labels_nv + labels_nn + labels_u
scores_all = scores_nv + scores_nn + scores_u
colors = ['skyblue'] * len(scores_nv) + ['salmon'] * len(scores_nn) + ['seagreen'] * len(scores_u)
x = np.arange(len(labels_all))

plt.figure(figsize=(18, 6))
plt.bar(x, scores_all, color=colors)
plt.xticks(x, labels_all, rotation=45, ha='right')

plt.axhline(y=avg_nv, color='blue', linestyle='--', label=f'Avg Nounâ€“Verb: {avg_nv:.2f}')
plt.axhline(y=avg_nn, color='red', linestyle='--', label=f'Avg Nounâ€“Noun: {avg_nn:.2f}')
plt.axhline(y=avg_u, color='green', linestyle='--', label=f'Avg Unambiguous: {avg_u:.2f}')

plt.title("Cosine Similarity Across Word Types")
plt.ylabel("Cosine Similarity")
plt.legend()
plt.tight_layout()
plt.show()